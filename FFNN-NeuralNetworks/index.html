
<!DOCTYPE html>
<html>
    <head>
    <title>The beautiful simplicity and powerfulness of feedforward Neural Networks | Thomas Haverford</title>
        <meta charset="utf-8"/>
        <link rel="stylesheet" type="text/css" href="../style.css">
        <link rel="icon" href="../res/2467883_08350.gif">
    </head>
    <body>
        <div class="crt">
        <div class="box">
        <h1>The beautiful simplicity and powerfulness of feedforward Neural Networks</h1>
        <h2>Table of contents</h2>
        <div class="TOC">
        <ul>
            <li><a href="#section1">"A Neural network? Like.. the brain?"</a></li>
            <li><a href="#section2">Feedforward Neural networks: At first glance</a></li>
            <li><a href="#section3">Mechanism of Feedforward Neural Networks</a></li>
            <ul>
                <li><a href="#section3.1">Each Individual Layer</a></li>
            </ul>
        </ul>
        </div>
        <p>
            I haven't been working on this website, posting anything, or really updating it due to my obsession with the topic of deeplearning. Deeplearning is a whole
            can of worms onto itself, but for simplicity sakes, we'll simply refer to it as Neural Networks.
        </p>

        <p>
            There are many types of Neural Networks that are geared towards one specific type of task, but in this post, we'll talk about feedforward Neural Networks.
        </p>

        <h2 id="section1">"A Neural network? Like.. the brain?"</h2>
        <p>
            Neural Networks are loosely inspired by our own biological Neural Networks as humans. These are the fundamental building blocks of how we as human beings learn and grow
            as a person. You might know the term 'Neural Networks' based on a pop-article explaining how ChatGPT worked on a surface level.
        </p>

        <p>
            Feedforward Neural Networks and biological Neural Networks have their differences and work in fundamentally different ways. So throwout your entire understanding of the human brain
            and learn about FFNNs (feedforward Neural Networks) as it's own entity.
        </p>
        <h2 id="section2">Feedforward Neural networks: At first glance</h2>
        <p>
            Feedforward Neural Networks are the defacto of machine learning, the process of training computers to learn from data and deal with unknown future input.
            A good example of this is spam-detection. Back then, (primarily in the 2000's) we had to use rule-based programs to detect and remove spam. This mean't detecting for
            common keywords such Spam emails would use such as 'FREE%%' or 'BUY 1 AND SELL 1' (phrase) and etc.
        </p>
        <p>
            However, as computers change, people change. And as people change, so does spam. These programs would quickly get very complicated as a byproduct of having to counter every
            spam email and edge case.
        </p>
        <p>
            Somewhere along the way, the industry found out you can use such FFNNS to not only train it on spam emails, but it can detect future spam emails (wih 98% accuracy) sometimes without even
            having to retrain it. These FFNNs were eventually the snowball which led to a variety of other use cases.
        </p>
        <p>
            These days, Feedforward Neural Networks are used for a variety of tasks including sentiment analysis, image classification (Although, convolutional Neural Networks have taken their place, seperate post for another time.),
            Some parts of video game NPCs, etc.
        </p>
        <h2 id="section3">Mechanism of Feedforward Neural Networks</h2>
        <p>
            You might think that this technology requires satanic freemasonry black-magic from the dark-order in order to get right, but in reality, it's simply a bunch of addition and multiplication with a slice of calculus all chained together
            to get the 'intelligence' factor as a byproduct.
        </p>
        <div class="png">
        <a href="https://learnopencv.com/wp-content/uploads/2017/10/mlp-diagram.jpg"><img src="https://learnopencv.com/wp-content/uploads/2017/10/mlp-diagram.jpg"></a>
        </div>

        <p>
            Neural Networks can be divided into 3 parts:
        </p>
        <p>
            <div class="quote">
            - The Input Layer (Takes in Data) <br>
            - The Hidden Layer (Also known as the Thinking layer which transforms data) <br>
            - The output Layer (Spits out the Output) <br>
            </div>
        </p>

        <h3 id="section3.1">Each individual Layer</h3>
        <p>
            Each layer has it's own respective purpose. The Input layer's job is to take in Data to be transformed before being sent into the Hidden Layer.
            The Input layer typically take's in vectors (also known as tensors) which look like this in format: {0, 0}. This vector is then sent into the Input layer
            and transformed to what's essentially a new vector.
        </p>
        <p>
            The Hidden Layer will then receive this data and transform it (using Activation function, coming up). This newly transformed data is then sent into the OutputLayer
            which represents what the "conclusion" the HiddenLayer is 'thinking' of. For instance, if you're dealing with a spam network, and this information is being processed to the Hidden Layer,
            a trained network's hidden layer will process it and see it is spam, then it'll send the right signal to the OutputLayer indicating that it is indeed spam.
        </p>
        <p>
            The bottom line is:
        </p>
        <p>
            <div class="quote">
                Input Layer - Receives Data <br>
                Hidden Layer - Computes and derives conclusion from data <br>
                Output Layer - Represents conclusion of data from HiddenLayer <br>
            </div>
        </p>
        <h3>Weights and biases</h3>
        <p>
            I talk about how this data is 'transformed' and 'processed' before being sent into another layer. But, this is vague language, what does it actually mean?
            You see, each and every Neuron has a 'weight' and a 'bias' which is connected to another neuron typically in the next Layer. 'Weights and biases' are also referred to
            as the individual 'parameters' in the network, otherwise the arguments of how to transform data before being passed.
        </p>
        <p>
            <div class="quote">
                Weights - Numerical Strength connection between Neuron A and Neuron B <br>
                Bias - Offset to add to the activated value <br>
            </div>
        </p>
        <p>
            Weights represent how 'strong' the connection between 2 Neurons are. This is done on purpose so that way when data is transformed, the neurons which have a 'strong' weight connection
            will have a higher activation sum, and therefore make the most amount of impact on the output. Weights are the foundamental building block to how Neural Networks learn and make the correct output.
            Whereas, a bias's job is to 'offset' the activation value by adding to it. Let's say the activation sum between 2 neurons is 0.4 and the bias is 0.1, well, adding to it, we'll get 0.5.
        </p>
        <p>
            Biases are typically used to slightly offset the output of a network without having to train it to it's absolute precise target output (Output we want the network to give us). This is we don't have to
            train the network to absolute perfection and risk overfitting (Training the network too much to the point where it misses the mark).
        </p>
        <h3>Activation sum</h3>
        <p>
            How are weights and biases added with respect to data before being sent into the next Layer? This is known as the activation sum.
        </p>
        <p>
            The general intuition of the weighted sum is this: Imagine you have a vector which has values {1, 2, 3}. You pass this into the Input Layer with 1 perceptron (or Neuron). Let's say the single weight of this perceptron is 0.40 (no bias), what happens?
            What you essentially get is {0.4, 0.8, 1.2}. What happened?
        </p>
        <p>
            Mathematically, this is what happened:
        </p>
        <p>
            <div class="quote">
                x = f(w * x1, w * x2, w * x3) + 0
            </div>
        </p>
        <p>
            If you're not mathematical at heart, this basically means that the perceptron took every value in the vector, and multiplied it with the corresponding weight. The exact same process is repeated for every perceptron when dealing with multineuron network. Say a network with
            5 neurons, 12 hidden neurons, 3 output Neurons, or otherwise..
        </p>
        <p>
            <div class="quote">
                y = f(y * w + b) <br>
            </div>
        </p>
        <p>
            Where <i>y</i> is the output and <i>w</i> represents a single weight and <i>b</i> represents a single bias. The input is multiplied by our weight then adds the bias to it.
            This activation formula is stretched out for every single Neuron and input coefficent before being sent into the next layer.
        </p>
        <p>
            If this does not make much sense to you or leaves you off with some questions and confusion, do not worry, it will all make sense once you see the full implementation of it later on.
        </p>
        <h3>Non-Linear activation sums</h3>
        <p>
            "What, there's more?! I thought you just covered activation sums!" Yes yes, but there is just one tiny thing I would like to mention. Activation sums are typically 'squished' so to speak into a value. You see, in most neural networks, the raw weighted sum
            is rarely just used, it's normally processed through another function of sorts with the goal of introducing what neural networks excel at: <i>Non-Linearity</i>.
        </p>
        <p>
            You see, if we take our function:
        </p>
        <p>
            <div class="quote">
                y = f(y * w + b) <br>
            </div>
        </p>
        <p>
            Then we plot it on desmos, the function will look like this:
        </p>
        <div class="png">
            <a href="../res/linearneural.PNG"><img src="../res/linearneural.PNG"></a>
        </div>
        <p>
            What you see here is a relatively linear but slanted line which scales upwards. Anybody that's had a little bit of experience knows that this is pretty much what aa linear regressor looks like (seperate topic!).
        </p>
        <p>
            Why is this a problem? Well, this prohibits the Neural Network from learning more complex patterns. By simply using the raw weighted sum, the only ability we have is training it to do tasks which involve upscale regression patterns such as predicting house-prices,
            predicting numbers, measurements, etc. Those have their practical advantage, but what if we want to do more complex and impressive stuff such as simulating logic gates, classifying images between a cat or a dog, sentiment analysis, etc. At this point, the model could not possible
            learn this. This is solved by introducing non-linearity.
        </p>
        <p>
            How do we introduce non-linearity? Well, there's a million ways. There's many function thats you can use to do this topic and it highly depends on the task that you want your neural network to be trained on.
        </p>
        <p>
            For most tasks thats not a regressor, you should go with sigmoid and start from there. The sigmoid function is defined as such:
        </p>
        <p>
            <div class="quote">
                s(x) = 1 / 1 + (math.exp(-x))
            </div>
        </p>
        <p>
            Let's see how this looks when applied to our model:
        </p>
        <div class="png">
            <a href="../res/nonlinearneural.PNG"><img src="../res/nonlinearneural.PNG"></a>
        </div>
        <p>
            Woah, super cool right? What just happened though?
        </p>
        <p>
            2 things, the network now has a 'slanted point', a position where it stables out a bit without increasing leading to non-regression. This makes training much easier to do. And it also has a point where it increases rapidly, this optimizes the training time considerably
            and make's finding the proper weights for the model much faster (known as gradient descent).
        </p>
        <p>
            You can copy the desmos code yourself and play around with it. If all this still does not make sense, again, it will. The best way to learn deeplearning is to <i>do</i> deeplearning and apply it to practical examples.
        </p>
        <p>
            Keep in mind that sigmoid is just one of many functions that youu can use to introduce non-linearity. Not all non-linear functions are created equal however. Different functions have different advantages and disadvantages. There's ReLu, tanh, sigmoid, softmax, ELU, etc.
        </p>
        <h2>FFNN: Training</h2>
        <p>
            How do these Networks 'learn' per say? We'll again, weights and biases (parameters) are the ultimate building blocks to what makes the prediction/output what it is. So, learning is basically just training the network how to adjust the weights in such a way that you get the
            output that you want, thus an increase in accuracy.
        </p>
        <p>
            There is a million different ways you can do training, not all of them are created equally though.
        </p>
        <p>
            Some ways of training are efficient and fast with tradeoffs from accuracy, someways are more precise, etc.
        </p>
        <p>
            To understand training, you must understand the training loop. Applying this to a practical example means letting the network first make a prediction. 9.9/10 the prediction will be incorrect, especially as your weights are starting off
            from a completely random value (weight initialization is it's own can of worms). The training loop is as follows:
        </p>
        <p>
            <div class="quote">
                - Let the model make a prediction -> Compute how wrong it is (loss function) -> Adjust weights with respect to loss -> Make another prediction -> repeat..
            </div>
        </p>
        <p>
            A more visual representation of this would be:
        </p>
        <div class="png">
            <a href="https://miro.medium.com/v2/resize:fit:1400/1*SCz0aTETjTYC864Bqjt6Og.png"><img src="https://miro.medium.com/v2/resize:fit:1400/1*SCz0aTETjTYC864Bqjt6Og.png"></a>
        </div>
        <h2> Loss functions </h2>
        <p>
            Loss functions are literally just that, functions which compute how wrong the prediction is. There are various loss functions which are used for different types of tasks. But the most common and simplest one is MSE (Mean squared Error).
            This is simple the function just looks like this in practice:
        </p>
        <p>
        <div class="quote">
            y^ = (y^ - y)^2
        </div>
        </p>
        <p>
            Where <i>y^</i> represents the model's prediction guess, and <i>y</i> represents the target Prediction we want the model to make. We square by 2 for the purposes of heavily penalizing
            even smaller errors. MSE is basically just the distance from another prediction squared by itself, no more, no less.
        </p>
        <p>
            Of course, this is just one of many Loss functions. There's also cross-entropy, binary cross-entropy, etc. You might of noticed by now that there are various ways of doing loss functions and introducing non-linearity, this can get all very confusing on what to use.
            Decision paralysis! I'll write a seperate post on this, explaining how to know which setup to use relative to your task.
        </p>
        <h2>Weight adjusting</h2>
        <p>
            Weight adjusting is also known as "optimization" in the world of deeplearning. As stated before, there are various different ways to do optimization. But what we will focus on in this post is the most used and widely adopted.
        </p>
        <h3>Gradient based optimization</h3>
        <p>
            Gradient based optimization is the process of calculating gradient (derivative with respect to loss function) in such that you can adjust a weight to change the prediction. It effectively answers this question:
        </p>
        <p>
            <div class="quote">
                "If I move the weight by X much, how much will it affect the prediction?"
            </div>
        </p>
        <p>
            This is the general intuition that you need to go from. This is all a gradient is, a derivative of sorts which tells the weight it's 'pointed' where to move in order to get the best prediction.
        </p>
        <p>
            In other words, we are trying to get the lowest cost function, the lowest distance from our prediction and target output.
        </p>
        <p>The process of adjusting weights via a gradient optimized way to get to the lowest cost function is known as <b><i>Gradient descent</i></b>, a core concept in deep-learning. Visually it looks like this: </p>
        <div class="png">
            <div class="boximg">
            <a href="https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/national/gradient-descent-convex-function.png"><img src="https://builtin.com/sites/www.builtin.com/files/styles/ckeditor_optimize/public/inline-images/national/gradient-descent-convex-function.png"></a>
            </div>
        </div>
        <p>
            This image is my favorite gradient descent image (<i>I know, odd thing to say</i>). That's in a sense that it's great at demonstrating the intuition you should have for it. Think of weights and biases as simply arrows in 3D space. Depending on the value of these parameters, they place you somewhere on the coordinate space.
            Your goal here, is to move "tug" on these parameters in a direction which will move you lower and lower on the plane, until you reach what is known as the <i>local maxima</i>, the lowest point relative to the closest to the parameters.
        </p>
        <p>
            To be a bit more mathematical on this, a "gradient" is simply a way to calculate a derivative of loss with respect to the weights. There is various different ways that you can calculate a gradient in the world of calculus and machine learning.
            You can do analytical derivation which uses rule-based logic to see which point gets you the most accurate point in space before going 'down'. You can also use numerical derivation which is more accurate, and efficient.
        </p>
        <h3>One fundamental problem</h3>
        <p>
            Keep in mind that some gradient descent algorithms are notorious for calculating what I stated above, <i>the local maxima</i>. Although on the surface, this is good, sometimes thel ocal maxima isn't <b>THE</b> lowest. Sometime's it reaches a low, but it's ultimately stuck there.
            This article is dedicated to neural networks and building a toy one yourself to experiment with, so I won't go too indepth on gradients, derivatives, etc, I'll simply give you the bare minimum that you can experiment with.
        </p>

        <h3>In summary</h3>
        <p>
            Phew! That was a lot of theory. Did you take notes? Don't worry, you can just grab mine:
        </p>

        <p>
            <div class="quote">
                Weights/biases = Parameters of a model, building block what adds up to the prediction <br>
                <br>
                Non-Linearity = Functions which break regression scales that build upwards in-order to allow the network to learn more complex patterns <br>
                <br>
                Weighted-Sum = The total weighted output of a specific layer after the input was processed through each neuron of said layer <br>
                <br>
                Activation = Function which transforms the input with respect to neuron's parameters.<br>
                <br>
                Training = Subset of algorithms which automatically adjust weights/biases to improve the model for better predictions on a given dataset. <br>
                <br>
                Gradient = Derivative of loss with respect to model's parameters <br>
                <br>
                Cost function = Function which calculates how far off the model was from the output it needs to give <br>
            </div>
        </p>

        <h2>Feedforward Neural Networks: A Practical implementation</h2>
        <p>
            If you are still stuck on understanding the core mechanisms and theory behind Neural Networks, do not worry, I once was as well. Neural Networks are just inherently mathematical in nature,
            and the best way to understand mathematics is by seeing the concept in practical application, rather than in vague abstract equation soup.
        </p>
        <p>
            In here, I will show you pseudo code that allows you to actually think and translate to your code, so that way you are not blindly-copying. Make sure you absolutely understand everything thats going on even in microsteps before you write down what you see.
            As doing otherwise will result in you looking at what essentially feels like somebody else's code. Even go back and rewrite the model by yourself if that helps increase understanding, but never blindly copy.
        </p>
        </div>
        <div class="blinkie-sect">
        <img src="../res/a92.gif"><img src="../res/norton2.gif"><img src="../res/h40.gif"><img src="../res/y53.gif"><img src="../res/y29.gif"><img src="../res/k27.gif">
        </div>
        <div class="copyright">
            <img src="../res/footerline.gif">
            Â© 2026 T.E. Havorford (<a href="https://www.ThomasE.xyz">ThomasE.xyz</a>)
        </div>
        </div>
    </body>
</html>